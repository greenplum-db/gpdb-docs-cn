<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Always force latest IE rendering engine or request Chrome Frame -->
  <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">

  
  <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,400italic,400,600' rel='stylesheet' type='text/css'>
  <!-- Use title if it's in the page YAML frontmatter -->
  <title>
      系统配置 |
    Greenplum Database Docs
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link href="/stylesheets/all.css" rel="stylesheet" media="screen, print" />
  <link href="/stylesheets/print.css" rel="stylesheet" media="print" />
  <link href='/images/favicon.ico' rel='shortcut icon'>

  <script src="/javascripts/all.js"></script>
  
</head>

<body class="x6-0 x6-0_best_practices x6-0_best_practices_sysconfig has-subnav">

<div class="viewport">
  <div class='wrap'>
    <script type="text/javascript">
      document.domain = "greenplum.org";
    </script>

     
  <header class="header header-layout">
    <h1 class="logo">
      <a href="/">Greenplum Database Documentation</a>
    </h1>
    
    <div class="header-links js-bar-links">
      <div class="btn-menu" data-behavior="MenuMobile"></div>
      <div class="header-item"><a href="https://greenplum.org">Back to Greenplum Database</a></div>
      <div class="header-item">
        <a href="https://github.com/greenplum-db/gpdb/wiki">Wiki</a>
      </div>
      
    </div>
  </header>


    <div class="container">

      <!--googleoff: index-->
      <div id="sub-nav" class="nav-container js-sidenav" role="navigation" >
  <a class="sidenav-title" data-behavior="SubMenuMobile">
    Doc Index
  </a>
  <div class="nav-content">
    
  <ul>
    
      <li class="">
        <a href="/v6/best_practices/../../v6/homenav.html">Greenplum数据库® 6.0文档</a>
        

      </li>
    
      <li class="has_submenu">
        <a href="/v6/best_practices/intro.html">Greenplum数据库最佳实践</a>
        
  <ul>
    
      <li class="">
        <a href="/v6/best_practices/summary.html">最佳实践概要</a>
        

      </li>
    
      <li class="">
        <a href="/v6/best_practices/sysconfig.html">系统配置</a>
        

      </li>
    
      <li class="">
        <a href="/v6/best_practices/schema.html">模式设计</a>
        

      </li>
    
      <li class="">
        <a href="/v6/best_practices/resgroups.html">采用资源组管理内存和资源</a>
        

      </li>
    
      <li class="">
        <a href="/v6/best_practices/workloads.html">采用资源队列管理内存和资源</a>
        

      </li>
    
      <li class="has_submenu">
        <a href="/v6/best_practices/maintenance.html">系统监控和维护</a>
        
  <ul>
    
      <li class="">
        <a href="/v6/best_practices/analyze.html">用ANALYZE更新统计信息</a>
        

      </li>
    
      <li class="">
        <a href="/v6/best_practices/bloat.html">管理数据库膨胀</a>
        

      </li>
    
      <li class="">
        <a href="/v6/best_practices/logfiles.html">监控Greenplum数据库日志文件</a>
        

      </li>
    
  </ul>


      </li>
    
      <li class="">
        <a href="/v6/best_practices/data_loading.html">装载数据</a>
        

      </li>
    
      <li class="">
        <a href="/v6/best_practices/security.html">安全性</a>
        

      </li>
    
      <li class="">
        <a href="/v6/best_practices/encryption.html">加密数据和数据库连接</a>
        

      </li>
    
      <li class="">
        <a href="/v6/best_practices/tuning_queries.html">SQL查询调优</a>
        

      </li>
    
      <li class="">
        <a href="/v6/best_practices/ha.html">高可用性</a>
        

      </li>
    
  </ul>


      </li>
    
  </ul>


  </div>
</div>

      <!--googleon: index-->

      <main class="content content-layout" id="js-content" role="main">
        <a id="top"></a>
        
          <h1 class="title-container" style="display: none;">
    系统配置
  </h1>

          <div id="js-quick-links" >
            
          </div>
        <div class="to-top" id="js-to-top">
          <a href="#top" title="back to top"></a>
        </div>
        

  <h1 class="title topictitle1">系统配置</h1>

  
  <div class="body">
<p class="shortdesc">这一节的主题描述配置Greenplum数据库集群主机的要求和最佳实践。</p>

    <p class="p">通常使用root用户配置Greenplum数据库集群。</p>

    <div class="section" id="topic_dt3_fkv_r4__topic_fvc_zh1_b2b">
<h2 class="title sectiontitle">配置时区</h2>
      
      <p class="p">Greenplum数据库会从存储在PostgreSQL内部的一个时区集合种选择一个时区使用。PostgreSQL中存储的可用时区
        全部取自于Internet Assigned Numbers Authority (IANA) 时区数据库，一旦PostgreSQL的IANA数据库发生
        改变，Greenplum数据库也会随之更新它的可用时区列表。</p>

      <p class="p">Greenplum通过将用户定义的时区与PostgreSQL的时区进行匹配来选择自身的时区，如果用户时区没配置，则会采用
        操作系统主机时区。例如，当选择默认时区时，Greenplum会基于主机操作系统时区文件并根据算法来选择PostgreSQL
        的时区。如果系统时区包含闰秒信息，Greenplum数据库便不能用PostgreSQL的时区匹配到系统时区。这种情形下，
        Greenplum数据库会基于主机系统的相关信息来计算一个最佳的PostgreSQL时区匹配值。</p>

      <div class="p">作为最佳实践，应该配置Greenplum数据库和主机系统采用已知的被支持的时区。采用当前系统时区和Greenplum数据库
        时区文件（该信息可能自上次重启后已经从IANA数据库更新）来匹配，这样做可以设置好Greenplum数据库master和
        segment实例的时区，防止Greenplum数据库每次重启后都重新计算这个最佳匹配值。使用<samp class="ph codeph">gpconfig</samp>工具
        设置和显示Greenplum数据库时区。例如，以下命令显示Greenplum数据库时区并设置时区为<samp class="ph codeph">US/Pacific</samp>。
        <pre class="pre codeblock"># gpconfig -s TimeZone
# gpconfig -c TimeZone -v 'US/Pacific'</pre>

        修改时区后必须重启Greenplum数据库。重启Greenplum数据库的命令为<samp class="ph codeph">gpstop -ra</samp>。系统视图
        <samp class="ph codeph">pg_timezone_names</samp>提供Greenplum数据库时区相关的信息。</div>

    </div>


    <div class="section" id="topic_dt3_fkv_r4__file_system">
<h2 class="title sectiontitle">文件系统</h2>
      
      <div class="p">XFS是Greenplum数据库数据目录的最佳实践文件系统。XFS应该用下列选项挂载：
        <pre class="pre codeblock">rw,nodev,noatime,nobarrier,inode64</pre>
</div>

    </div>

    <div class="section" id="topic_dt3_fkv_r4__port_config">
<h2 class="title sectiontitle">端口配置</h2>
      
      <div class="p">
<samp class="ph codeph">ip_local_port_range</samp>应该被设置为不与Greenplum数据库端口范围冲突。例如，
          <samp class="ph systemoutput">/etc/sysctl.conf</samp>文件中的设置：
        <pre class="pre codeblock">net.ipv4.ip_local_port_range = 10000  65535</pre>
</div>

      <div class="p">客户可以设置Greenplum数据库基础端口号为下列值。<pre class="pre codeblock">PORT_BASE = 6000
MIRROR_PORT_BASE = 7000</pre>
</div>

    </div>

    <div class="section" id="topic_dt3_fkv_r4__io_config">
<h2 class="title sectiontitle">I/O配置</h2>
      
      <p class="p">在含有数据目录的设备上，blockdev预读尺寸应该被设置为16384。
        下列命令设置<samp class="ph codeph">/dev/sdb</samp>的预读值大小。</p>

      <pre class="pre codeblock"># /sbin/blockdev --setra 16384 /dev/sdb</pre>

      <p class="p">下列命令显示<samp class="ph codeph">/dev/sdb</samp>的预读值大小。</p>

      <pre class="pre codeblock"># /sbin/blockdev --getra /dev/sdb
16384</pre>

      <p class="p">应该为所有数据目录设备设置deadline IO调度器。</p>

      <pre class="pre codeblock"> # cat /sys/block/sdb/queue/scheduler
 noop anticipatory [deadline] cfq </pre>

      <div class="p">应该在<samp class="ph codeph">/etc/security/limits.conf</samp>文件中增加OS文件和进程的最大数量。
        <pre class="pre codeblock">* soft  nofile 65536
* hard  nofile 65536
* soft  nproc 131072
* hard  nproc 131072</pre>
</div>

      <div class="p">让内核文件输出到一个已知的位置并且确保<samp class="ph codeph">limits.conf</samp>允许输出内核文件。
        <pre class="pre codeblock">kernel.core_pattern = /var/core/core.%h.%t
# grep core /etc/security/limits.conf  
* soft  core unlimited</pre>
</div>

    </div>

    <div class="section" id="topic_dt3_fkv_r4__os_mem_config">
<h2 class="title sectiontitle">OS内存配置</h2>
      
      <p class="p">Linux中sysctl的变量<samp class="ph codeph">vm.overcommit_memory</samp>和<samp class="ph codeph">vm.overcommit_ratio</samp>
        影响操作系统管理内存分配的方式。这些变量应该按照下面的方式设置：</p>

      <div class="p">
<samp class="ph codeph">vm.overcommit_memory</samp>决定OS用于确定为进程可以分配多少内存的方法。这个变量应该总是被
        设置为2，它是对数据库唯一安全的设置。<div class="note note">
<span class="notetitle">Note:</span> 有关如何配置overcommit memory的信息，参见：
          <ul class="ul" id="topic_dt3_fkv_r4__ul_pgp_4hz_m1b">
            <li class="li"><a class="xref" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Memory_overcommitment&amp;sa=D&amp;ust=1499719618717000&amp;usg=AFQjCNErcHO7vErv4pn9fIhCxrR0XRiknA" target="_blank">https://en.wikipedia.org/wiki/Memory_overcommitment</a></li>

            <li class="li"><a class="xref" href="https://www.google.com/url?q=https://www.kernel.org/doc/Documentation/vm/overcommit-accounting&amp;sa=D&amp;ust=1499719618717000&amp;usg=AFQjCNEmu5tZutAaN1KCSlIwz4hwqihkOQ" target="_blank">https://www.kernel.org/doc/Documentation/vm/overcommit-accounting</a></li>

          </ul>
</div>
</div>

      <p class="p"><samp class="ph codeph">vm.overcommit_ratio</samp>是被用于应用进程的RAM的百分数。在Red Hat Enterprise Linux上默认是50。
        为这一变量计算最优值的公式可见<a class="xref" href="#topic_dt3_fkv_r4__segment_mem_config">资源队列的segment内存配置</a>。</p>

      <p class="p">不要启用操作系统大页设置。</p>

      <p class="p">另见<a class="xref" href="workloads.html#topic_hhc_z5w_r4" title="避免内存错误，管理Greenplum数据库资源。">采用资源队列管理内存和资源</a>。</p>

    </div>

    <div class="section" id="topic_dt3_fkv_r4__shared_mem_config">
<h2 class="title sectiontitle">共享内存设置</h2>
      
      <p class="p">Greenplum数据库使用共享内存在<samp class="ph codeph">postgres</samp>进程之间通信，这些进程是同一个<samp class="ph codeph">postgres</samp>
        实例的组成部分。下面的共享内存设置应该在<samp class="ph codeph">sysctl</samp>中设定并且很少会被修改。</p>

      <pre class="pre codeblock">kernel.shmmax = 500000000
kernel.shmmni = 4096
kernel.shmall = 4000000000</pre>

    </div>

    <div class="section" id="topic_dt3_fkv_r4__gpcheck">
<h2 class="title sectiontitle">验证操作系统</h2>
      
      <p class="p">运行<samp class="ph codeph">gpcheck</samp>来验证操作系统配置。更多信息请见<em class="ph i">Greenplum数据库工具指南</em>中的
        <samp class="ph codeph">gpcheck</samp>部分。</p>

    </div>

    <div class="section" id="topic_dt3_fkv_r4__host_segs">
<h2 class="title sectiontitle">每台主机上的Segment数量</h2>
      
      <p class="p">每台segment主机上运行的segment数量对总体系统性能有着巨大的影响。这些segment之间以及主机上的其他进程
        共享该主机的CPU核心、内存和网络接口。过高估计一台服务器能容纳的segment数量是导致非最优性能的常见原因。</p>

      <div class="p">在选择每台主机上运行多少Segment时必须要考虑的因素包括：<ul class="ul" id="topic_dt3_fkv_r4__ul_z44_qfp_y4">
        <li class="li">核心数量</li>

        <li class="li">安装在该服务器上的物理RAM容量</li>

        <li class="li">NIC数量</li>

        <li class="li">附加到服务器的存储容量</li>

        <li class="li">主segment和镜像segment的混合</li>

        <li class="li">将在主机上运行的ETL进程</li>

        <li class="li">运行在主机上的非Greenplum进程</li>

        </ul>
</div>

    </div>

    <div class="section" id="topic_dt3_fkv_r4__segment_mem_config">
<h2 class="title sectiontitle">资源队列的segment内存配置</h2>
      
      <div class="p">
<samp class="ph codeph">gp_vmem_protect_limit</samp>服务器配置参数指定单个segment的所有活动postgres进程在
        任何给定时刻能够消耗的内存量。查询一旦超过该值则会失败。可使用下面的计算方法为<samp class="ph codeph">gp_vmem_protect_limit</samp>
        估计一个安全值。<ol class="ol" id="topic_dt3_fkv_r4__ol_osx_srq_kv">
          <li class="li">使用这个公式计算<samp class="ph codeph">gp_vmem</samp>（Greenplum数据库可用的主机内存）：
            <pre class="pre codeblock">gp_vmem = ((SWAP + RAM) – (7.5GB + 0.05 * RAM)) / 1.7</pre>

            其中<samp class="ph codeph">SWAP</samp>是主机的交换空间（以GB为单位）而<samp class="ph codeph">RAM</samp>是主机上安装的
            内存（以GB为单位）。</li>

          <li class="li">计算<samp class="ph codeph">max_acting_primary_segments</samp>。当镜像segment由于集群中其他主机上的
            segment或者主机故障而被激活时，这是能在一台主机上运行的主segment的最大数量。例如，对于布置在
            每台主机有8个主segment的四主机块中的镜像来说，单一segment主机失效将会在其所在块中剩余每台主机
            上激活2个或者3个镜像segment。这一配置的<samp class="ph codeph">max_acting_primary_segments</samp>值是11
            （8个主Segment外加3个故障时激活的镜像）。</li>

          <li class="li">通过将总的Greenplum数据库内存除以活动主segment的最大数量来计算<samp class="ph codeph">gp_vmem_protect_limit</samp>：
            <pre class="pre codeblock">gp_vmem_protect_limit = gp_vmem / max_acting_primary_segments</pre>

            转换成兆字节就是<samp class="ph codeph">gp_vmem_protect_limit</samp>系统配置参数的设置。</li>

        </ol>

      </div>

      <div class="p" dir="ltr">对于有大量工作文件产生的场景，可调整<samp class="ph codeph">gp_vmem</samp>的计算以增加工作文件条件：
        <pre class="pre codeblock">gp_vmem = ((SWAP + RAM) – (7.5GB + 0.05 * RAM - (300KB * <var class="keyword varname">total_#_workfiles</var>))) / 1.7</pre>
</div>

      <p dir="ltr" class="p">有关监控和管理工作文件使用的信息请见<em class="ph i">Greenplum数据库管理员指南</em>。</p>

      <p dir="ltr" class="p">用户可以根据<samp class="ph codeph">gp_vmem</samp>的值计算操作系统参数
        <samp class="ph codeph">vm.overcommit_ratio</samp>的值：</p>

      <pre class="pre codeblock">vm.overcommit_ratio = (RAM - 0.026 * gp_vmem) / RAM</pre>

      <p class="p">更多有关vm.overcommit_ratio的信息请见<a class="xref" href="#topic_dt3_fkv_r4__os_mem_config">OS内存配置</a>。</p>

      <p class="p">另见<a class="xref" href="workloads.html#topic_hhc_z5w_r4" title="避免内存错误，管理Greenplum数据库资源。">采用资源队列管理内存和资源</a>。</p>

    </div>

    <div class="section" id="topic_dt3_fkv_r4__statement_mem_config">
<h2 class="title sectiontitle">资源队列语句内存配置</h2>
      
      <p class="p"><samp class="ph codeph">statement_mem</samp>服务器配置参数是分配给segment数据库中任何单个查询的内存量。如果一个
        语句要求额外的内存，它将溢出到磁盘。用下面的公式计算<samp class="ph codeph">statement_mem</samp>的值：</p>

      <p class="p">
        <samp class="ph codeph">(gp_vmem_protect_limit * .9) / max_expected_concurrent_queries </samp>
      </p>

      <p class="p">例如，如果<samp class="ph codeph">gp_vmem_protect_limit</samp>被设置为8GB（8192MB），对于40个并发查询，
        <samp class="ph codeph">statement_mem</samp>的计算可以是：</p>

      <p class="p">
        <samp class="ph codeph">(8192MB * .9) / 40 = 184MB</samp>
      </p>

      <p class="p">在每个查询被溢出到磁盘之前，它被允许使用184MB内存。</p>

      <p class="p">要安全地增加<samp class="ph codeph">statement_mem</samp>的值，用户必须增加<samp class="ph codeph">gp_vmem_protect_limit</samp>
        或者减少并发的查询数量。要增加<samp class="ph codeph">gp_vmem_protect_limit</samp>，用户必须增加物理RAM或者交换空间，
        也可以减少每台主机上的segment数量。</p>

      <p class="p">注意在集群中增加segment主机无助于内存不足错误，除非用户使用额外的主机来减少每台主机上的segment数量。
        </p>

      <p class="p">当不能提供足够的内存来映射所有的输出时，才会创建溢出文件。通常发生在缓存空间占据达到80%以上时。</p>

      <p class="p">另外，使用资源队列管理查询内存的最佳实践可参考<a class="xref" href="workloads.html#topic_hhc_z5w_r4" title="避免内存错误，管理Greenplum数据库资源。">资源管理</a>。</p>

    </div>

    <div class="section" id="topic_dt3_fkv_r4__spill_files">
<h2 class="title sectiontitle">资源队列溢出文件配置</h2>
      
      <p class="p">如果查询没有被分配足够的内存，Greenplum数据库会在磁盘上创建<em class="ph i">溢出文件</em>（也被称为<em class="ph i">工作文件</em>）。
        默认单个查询可以创建不超过100,000个溢出文件，这对大部分查询来说都是足够的。</p>

      <p class="p">用户可以用配置参数<samp class="ph codeph">gp_workfile_limit_files_per_query</samp>控制每个查询和每个segment
        创建的溢出文件最大数量。设置该参数为0将允许查询创建无限个溢出文件。限制允许的溢出文件数量可以防止失控的
        查询损坏系统。</p>

      <p class="p">如果一个查询没有被分配足够的内存或者被查询数据中存在数据倾斜，查询可能会生成大量溢出文件。如果查询创建
        超过指定数量的溢出文件，Greenplum数据库会返回这个错误：</p>

      <p class="p">
        <samp class="ph codeph">ERROR: number of workfiles per query limit exceeded</samp>
      </p>

      <p class="p">在增加<samp class="ph codeph">gp_workfile_limit_files_per_query</samp>的值之前，尝试通过更改查询、改变数据分布
        或者更改内存配置来降低溢出文件的数量。</p>

      <p class="p"><samp class="ph codeph">gp_toolkit</samp>模式包括一些视图可以允许用户查看所有正在使用溢出文件的查询的信息。这些信息
        可以被用来排查故障以及查询调优：</p>

      <ul class="ul" id="topic_dt3_fkv_r4__ul_dyd_1qq_bp">
        <li class="li">
<samp class="ph codeph">gp_workfile_entries</samp>视图中包含当前在某个segment上使用工作文件的操作。有关操作
          的信息请见<a class="xref" href="tuning_queries.html#reading_explain_plan">如何阅读执行计划</a>。</li>

        <li class="li">
<samp class="ph codeph">gp_workfile_usage_per_query</samp>视图包含当前在某个segment上使用工作文件的查询。</li>

        <li class="li">
<samp class="ph codeph">gp_workfile_usage_per_segment</samp>视图为包含segment信息。每一行显示当前在该
          segment上用于工作文件的磁盘空间总量。</li>

      </ul>

      <p class="p">这些视图中列的描述请见<em class="ph i">Greenplum数据库参考指南</em>。</p>

      <p class="p"><samp class="ph codeph">gp_workfile_compression</samp>配置参数指定是否压缩溢出文件。默认设置为<samp class="ph codeph">off</samp>。
        启用压缩可以提高文件溢出时的性能。</p>

    </div>

  </div>

<div class="related-links">
<div class="familylinks">
<div class="parentlink">
<strong>Parent topic:</strong> <a class="link" href="intro.html">Greenplum数据库最佳实践</a>
</div>
</div>
</div>


        

      </main>
    </div>
  </div>
</div>

<div id="scrim"></div>

<div class="container">
  <footer class="site-footer-links">
    
  </footer>
</div><!--end of container-->

</body>
</html>
